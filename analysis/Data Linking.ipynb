{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c65a7e-2a2d-4521-b1a9-2d9edf161d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Set up data paths\n",
    "data_dir = Path('../data')\n",
    "usda_dir = data_dir / 'FoodData_Central_csv_2025-04-24'\n",
    "\n",
    "print(\"Loading datasets...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787f4e6e-dd57-4e0f-9465-c788e5192ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/nn1r9fg115dd94js8h25w1yc0000gn/T/ipykernel_12953/2645093397.py:8: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  food_nutrient_df = pd.read_csv(usda_dir / 'food_nutrient.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (500, 159)\n",
      "Intensity matrix shape: (54546, 526)\n",
      "USDA food shape: (2064912, 5)\n",
      "SR Legacy food shape: (7793, 2)\n",
      "USDA food_nutrient shape: (26805037, 13)\n",
      "USDA nutrient shape: (477, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load the main datasets\n",
    "metadata_df = pd.read_csv(data_dir / 'Metadata_500food.csv')\n",
    "intensity_df = pd.read_csv(data_dir / 'featuretable_reformated - Kushal.csv')\n",
    "\n",
    "# Load USDA datasets including sr_legacy_food\n",
    "food_df = pd.read_csv(usda_dir / 'food.csv')\n",
    "sr_legacy_food_df = pd.read_csv(usda_dir / 'sr_legacy_food.csv')\n",
    "food_nutrient_df = pd.read_csv(usda_dir / 'food_nutrient.csv')\n",
    "nutrient_df = pd.read_csv(usda_dir / 'nutrient.csv')\n",
    "\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Intensity matrix shape: {intensity_df.shape}\")\n",
    "print(f\"USDA food shape: {food_df.shape}\")\n",
    "print(f\"SR Legacy food shape: {sr_legacy_food_df.shape}\")\n",
    "print(f\"USDA food_nutrient shape: {food_nutrient_df.shape}\")\n",
    "print(f\"USDA nutrient shape: {nutrient_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c489e0f-e9b5-4faf-9551-110ec007e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== METADATA ANALYSIS ===\n",
      "Unique sample_type_group5 values: 141\n",
      "Unique filenames: 500\n",
      "\n",
      "Sample_type_group5 distribution (top 10):\n",
      "  tea: 51 samples\n",
      "  beef: 34 samples\n",
      "  mouse: 14 samples\n",
      "  trout: 13 samples\n",
      "  pepper: 13 samples\n",
      "  orange: 13 samples\n",
      "  lettuce: 11 samples\n",
      "  coffee: 11 samples\n",
      "  soda: 10 samples\n",
      "  tomato: 10 samples\n",
      "\n",
      "ndb_number info:\n",
      "Non-null count: 500\n",
      "Unique ndb_numbers: 159\n",
      "Data type: object\n",
      "Sample values: ['14003', '45182628', '11215', '45096876', '11098']\n",
      "\n",
      "Sample filename to food mappings:\n",
      "P3_E8_G72464.mzML -> grain_fermented (ndb: 14003)\n",
      "P5_G5_G72471.mzML -> pea (ndb: 45182628)\n",
      "P3_C12_72475.mzML -> garlic (ndb: 11215)\n",
      "P3_B9_G72492.mzML -> raspberry (ndb: 45096876)\n",
      "P3_B8_G72493.mzML -> brussel sprout (ndb: 11098)\n",
      "P3_B7_72497.mzML -> melon (ndb: 9181)\n",
      "P3_B6_G72498.mzML -> pepper (ndb: 11979)\n",
      "P3_B5_72500.mzML -> apple (ndb: 9020)\n",
      "P5_G4_G72502.mzML -> chia (ndb: 45120594)\n",
      "P5_G2_G72503.mzML -> oat (ndb: 45057949)\n"
     ]
    }
   ],
   "source": [
    "# Analyze metadata structure\n",
    "print(\"=== METADATA ANALYSIS ===\")\n",
    "print(f\"Unique sample_type_group5 values: {metadata_df['sample_type_group5'].nunique()}\")\n",
    "print(f\"Unique filenames: {metadata_df['filename'].nunique()}\")\n",
    "\n",
    "# Show sample_type_group5 distribution\n",
    "print(\"\\nSample_type_group5 distribution (top 10):\")\n",
    "group5_counts = metadata_df['sample_type_group5'].value_counts().head(10)\n",
    "for food, count in group5_counts.items():\n",
    "    print(f\"  {food}: {count} samples\")\n",
    "\n",
    "# Check ndb_number availability and data type\n",
    "print(f\"\\nndb_number info:\")\n",
    "print(f\"Non-null count: {metadata_df['ndb_number'].notna().sum()}\")\n",
    "print(f\"Unique ndb_numbers: {metadata_df['ndb_number'].nunique()}\")\n",
    "print(f\"Data type: {metadata_df['ndb_number'].dtype}\")\n",
    "print(f\"Sample values: {metadata_df['ndb_number'].dropna().head().tolist()}\")\n",
    "\n",
    "# Show some example mappings\n",
    "print(\"\\nSample filename to food mappings:\")\n",
    "sample_data = metadata_df[['filename', 'sample_type_group5', 'ndb_number', 'ndb_description']].head(10)\n",
    "for _, row in sample_data.iterrows():\n",
    "    print(f\"{row['filename']} -> {row['sample_type_group5']} (ndb: {row['ndb_number']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3458404-0a39-4cad-bf91-7cad98a2e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SR LEGACY FOOD MAPPING ANALYSIS ===\n",
      "SR Legacy food unique fdc_ids: 7793\n",
      "SR Legacy food unique NDB numbers: 7793\n",
      "\n",
      "SR Legacy food columns:\n",
      "['fdc_id', 'NDB_number']\n",
      "\n",
      "NDB_number data type: int64\n",
      "Sample NDB_number values: [18634, 18635, 18637, 18639, 18932]\n",
      "\n",
      "Sample SR Legacy food mappings:\n",
      "fdc_id 167512 -> NDB_number 18634\n",
      "fdc_id 167513 -> NDB_number 18635\n",
      "fdc_id 167514 -> NDB_number 18637\n",
      "fdc_id 167515 -> NDB_number 18639\n",
      "fdc_id 167516 -> NDB_number 18932\n",
      "fdc_id 167517 -> NDB_number 18933\n",
      "fdc_id 167518 -> NDB_number 18934\n",
      "fdc_id 167519 -> NDB_number 18935\n",
      "fdc_id 167520 -> NDB_number 18942\n",
      "fdc_id 167521 -> NDB_number 18943\n",
      "\n",
      "Our metadata has 159 unique NDB numbers (as strings)\n",
      "Found 103 NDB numbers that match between metadata and SR Legacy\n",
      "Sample matching NDB numbers:\n",
      "  NDB 11241\n",
      "  NDB 15085\n",
      "  NDB 2038\n",
      "  NDB 11098\n",
      "  NDB 9156\n"
     ]
    }
   ],
   "source": [
    "# Analyze the SR Legacy food mapping\n",
    "print(\"=== SR LEGACY FOOD MAPPING ANALYSIS ===\")\n",
    "print(f\"SR Legacy food unique fdc_ids: {sr_legacy_food_df['fdc_id'].nunique()}\")\n",
    "print(f\"SR Legacy food unique NDB numbers: {sr_legacy_food_df['NDB_number'].nunique()}\")\n",
    "\n",
    "# Check the mapping structure\n",
    "print(\"\\nSR Legacy food columns:\")\n",
    "print(sr_legacy_food_df.columns.tolist())\n",
    "\n",
    "# Check NDB_number data type\n",
    "print(f\"\\nNDB_number data type: {sr_legacy_food_df['NDB_number'].dtype}\")\n",
    "print(f\"Sample NDB_number values: {sr_legacy_food_df['NDB_number'].dropna().head().tolist()}\")\n",
    "\n",
    "# Show some example mappings\n",
    "print(\"\\nSample SR Legacy food mappings:\")\n",
    "sample_sr = sr_legacy_food_df[['fdc_id', 'NDB_number']].head(10)\n",
    "for _, row in sample_sr.iterrows():\n",
    "    print(f\"fdc_id {row['fdc_id']} -> NDB_number {row['NDB_number']}\")\n",
    "\n",
    "# Check for our metadata ndb_numbers in SR Legacy (with type conversion)\n",
    "metadata_ndb_numbers = metadata_df['ndb_number'].dropna().astype(str).unique()\n",
    "print(f\"\\nOur metadata has {len(metadata_ndb_numbers)} unique NDB numbers (as strings)\")\n",
    "\n",
    "# Find matches in SR Legacy\n",
    "sr_ndb_numbers = sr_legacy_food_df['NDB_number'].dropna().astype(str).unique()\n",
    "matches = set(metadata_ndb_numbers).intersection(set(sr_ndb_numbers))\n",
    "print(f\"Found {len(matches)} NDB numbers that match between metadata and SR Legacy\")\n",
    "\n",
    "if matches:\n",
    "    print(\"Sample matching NDB numbers:\")\n",
    "    for ndb in list(matches)[:5]:\n",
    "        print(f\"  NDB {ndb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9002047b-1b62-4b73-a673-27a4fbd50885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTENSITY MATRIX ANALYSIS ===\n",
      "Features (rows): 54546\n",
      "Samples (columns): 526\n",
      "\n",
      "Feature column found with 54546 unique features\n",
      "Sample features: [271, 4396, 18754, 15057, 125441]\n",
      "\n",
      "Column names (first 10):\n",
      "['Feature', 'P4_C10_G75213.mzML Peak area', 'P4_F3_G75184.mzML Peak area', 'P3_F1_G74067.mzML Peak area', 'P4_D9_G75202.mzML Peak area', 'P2_F5_G83240.mzML Peak area', 'P1_B1_G75794.mzML Peak area', 'P2_E12_G83237.mzML Peak area', 'P2_D8_G87461.mzML Peak area', 'G73730.mzML Peak area']\n",
      "\n",
      "Found 524 peak area columns\n",
      "Sample peak area columns: ['P4_C10_G75213.mzML Peak area', 'P4_F3_G75184.mzML Peak area', 'P3_F1_G74067.mzML Peak area', 'P4_D9_G75202.mzML Peak area', 'P2_F5_G83240.mzML Peak area']\n"
     ]
    }
   ],
   "source": [
    "# Analyze intensity matrix\n",
    "print(\"=== INTENSITY MATRIX ANALYSIS ===\")\n",
    "print(f\"Features (rows): {intensity_df.shape[0]}\")\n",
    "print(f\"Samples (columns): {intensity_df.shape[1]}\")\n",
    "\n",
    "# Check if there's a Feature column\n",
    "if 'Feature' in intensity_df.columns:\n",
    "    print(f\"\\nFeature column found with {intensity_df['Feature'].nunique()} unique features\")\n",
    "    print(\"Sample features:\", intensity_df['Feature'].head().tolist())\n",
    "else:\n",
    "    print(\"\\nNo 'Feature' column found. Checking first column...\")\n",
    "    print(\"First column name:\", intensity_df.columns[0])\n",
    "    print(\"Sample values:\", intensity_df.iloc[:5, 0].tolist())\n",
    "\n",
    "# Show column structure\n",
    "print(f\"\\nColumn names (first 10):\")\n",
    "print(intensity_df.columns[:10].tolist())\n",
    "\n",
    "# Check for peak area columns (both cases)\n",
    "peak_area_cols = [col for col in intensity_df.columns if 'peak area' in col.lower()]\n",
    "print(f\"\\nFound {len(peak_area_cols)} peak area columns\")\n",
    "if peak_area_cols:\n",
    "    print(\"Sample peak area columns:\", peak_area_cols[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091312d3-e46b-4506-93eb-3fba203ce3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SELECTING RANDOM FOODS FOR TESTING ===\n",
      "Total unique foods: 141\n",
      "\n",
      "Selected random foods: ['sweet potato', 'langostino', 'kohlrabi']\n",
      "\n",
      "Found 9 samples for these foods:\n",
      "  sweet potato: 6 samples\n",
      "  langostino: 2 samples\n",
      "  kohlrabi: 1 samples\n"
     ]
    }
   ],
   "source": [
    "# Pick a couple of random foods for testing\n",
    "print(\"=== SELECTING RANDOM FOODS FOR TESTING ===\")\n",
    "\n",
    "# Get unique foods from sample_type_group5\n",
    "unique_foods = metadata_df['sample_type_group5'].dropna().unique()\n",
    "print(f\"Total unique foods: {len(unique_foods)}\")\n",
    "\n",
    "# Pick 3 random foods\n",
    "random_foods = random.sample(list(unique_foods), 3)\n",
    "print(f\"\\nSelected random foods: {random_foods}\")\n",
    "\n",
    "# Get all samples for these foods\n",
    "test_foods_data = metadata_df[metadata_df['sample_type_group5'].isin(random_foods)]\n",
    "print(f\"\\nFound {len(test_foods_data)} samples for these foods:\")\n",
    "for food in random_foods:\n",
    "    food_samples = test_foods_data[test_foods_data['sample_type_group5'] == food]\n",
    "    print(f\"  {food}: {len(food_samples)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc73027-f66a-4513-8f37-c176b9332fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING INTENSITY LINKING ===\n",
      "Testing with food: sweet potato\n",
      "Found 6 samples\n",
      "Using sample filename: P2_E1_G87553.mzML\n",
      "Looking for intensity columns:\n",
      "  Lower case: P2_E1_G87553.mzML peak area\n",
      "  Upper case: P2_E1_G87553.mzML Peak area\n",
      "✓ Found upper case intensity column!\n",
      "Found 10516 features with non-zero intensity\n",
      "Intensity range: 12.35 to 91609544.00\n",
      "\n",
      "Top 10 features by intensity:\n",
      "  Feature 1754.0: 91609544.00\n",
      "  Feature 1065.0: 75991500.00\n",
      "  Feature 3407.0: 23949620.00\n",
      "  Feature 1638.0: 15438614.00\n",
      "  Feature 1409.0: 12766388.00\n",
      "  Feature 2420.0: 9508895.00\n",
      "  Feature 942.0: 8696197.00\n",
      "  Feature 1474.0: 8645326.00\n",
      "  Feature 7428.0: 8447453.00\n",
      "  Feature 247010.0: 7921888.00\n"
     ]
    }
   ],
   "source": [
    "# Test intensity linking for one food\n",
    "print(\"=== TESTING INTENSITY LINKING ===\")\n",
    "\n",
    "test_food = random_foods[0]\n",
    "print(f\"Testing with food: {test_food}\")\n",
    "\n",
    "# Get all samples for this food\n",
    "food_samples = metadata_df[metadata_df['sample_type_group5'] == test_food]\n",
    "print(f\"Found {len(food_samples)} samples\")\n",
    "\n",
    "# Get the first sample's filename\n",
    "sample_filename = food_samples.iloc[0]['filename']\n",
    "print(f\"Using sample filename: {sample_filename}\")\n",
    "\n",
    "# Look for the intensity column (try both cases)\n",
    "intensity_col_lower = f\"{sample_filename} peak area\"\n",
    "intensity_col_upper = f\"{sample_filename} Peak area\"\n",
    "\n",
    "print(f\"Looking for intensity columns:\")\n",
    "print(f\"  Lower case: {intensity_col_lower}\")\n",
    "print(f\"  Upper case: {intensity_col_upper}\")\n",
    "\n",
    "# Check which one exists\n",
    "if intensity_col_lower in intensity_df.columns:\n",
    "    intensity_col = intensity_col_lower\n",
    "    print(\"✓ Found lower case intensity column!\")\n",
    "elif intensity_col_upper in intensity_df.columns:\n",
    "    intensity_col = intensity_col_upper\n",
    "    print(\"✓ Found upper case intensity column!\")\n",
    "else:\n",
    "    print(\"✗ Neither intensity column found\")\n",
    "    # Show available columns that might match\n",
    "    matching_cols = [col for col in intensity_df.columns if sample_filename in col]\n",
    "    print(f\"Available columns containing '{sample_filename}': {matching_cols}\")\n",
    "    intensity_col = None\n",
    "\n",
    "if intensity_col:\n",
    "    # Get all feature intensities for this sample\n",
    "    feature_intensities = intensity_df[['Feature', intensity_col]].copy()\n",
    "    feature_intensities = feature_intensities.rename(columns={intensity_col: 'intensity'})\n",
    "    \n",
    "    # Remove rows where intensity is 0 or NaN\n",
    "    feature_intensities = feature_intensities[\n",
    "        (feature_intensities['intensity'] > 0) & \n",
    "        (feature_intensities['intensity'].notna())\n",
    "    ]\n",
    "    \n",
    "    print(f\"Found {len(feature_intensities)} features with non-zero intensity\")\n",
    "    print(f\"Intensity range: {feature_intensities['intensity'].min():.2f} to {feature_intensities['intensity'].max():.2f}\")\n",
    "    \n",
    "    # Show top features by intensity\n",
    "    print(\"\\nTop 10 features by intensity:\")\n",
    "    top_features = feature_intensities.nlargest(10, 'intensity')\n",
    "    for _, row in top_features.iterrows():\n",
    "        print(f\"  Feature {row['Feature']}: {row['intensity']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ddefde-615c-43b3-92b0-e389eb351700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING USDA NUTRITIONAL DATA LINKING ===\n",
      "Testing with food: potato\n",
      "NDB Number: 11365 (type: <class 'str'>)\n",
      "✓ Found SR Legacy match: fdc_id 170438\n",
      "✓ Found 98 nutrient entries\n",
      "\n",
      "Nutrient data for potato:\n",
      "  SFA 4:0: 0.0 G\n",
      "  PUFA 18:3: 0.01 G\n",
      "  Carotene, alpha: 0.0 UG\n",
      "  Fluoride, F: 49.4 UG\n",
      "  PUFA 18:4: 0.0 G\n",
      "  Vitamin E (alpha-tocopherol): 0.01 MG\n",
      "  Potassium, K: 379.0 MG\n",
      "  SFA 12:0: 0.003 G\n",
      "  Carbohydrate, by difference: 20.13 G\n",
      "  PUFA 22:6 n-3 (DHA): 0.0 G\n"
     ]
    }
   ],
   "source": [
    "# Test USDA nutritional data linking\n",
    "print(\"=== TESTING USDA NUTRITIONAL DATA LINKING ===\")\n",
    "\n",
    "# Get a sample with ndb_number\n",
    "sample_with_ndb = metadata_df[metadata_df['ndb_number'].notna()].iloc[45]\n",
    "test_food = sample_with_ndb['sample_type_group5']\n",
    "ndb_number = sample_with_ndb['ndb_number']\n",
    "\n",
    "print(f\"Testing with food: {test_food}\")\n",
    "print(f\"NDB Number: {ndb_number} (type: {type(ndb_number)})\")\n",
    "\n",
    "# Step 1: Find fdc_id in SR Legacy food (convert to string for comparison)\n",
    "sr_legacy_match = sr_legacy_food_df[sr_legacy_food_df['NDB_number'].astype(str) == str(ndb_number)]\n",
    "\n",
    "if not sr_legacy_match.empty:\n",
    "    fdc_id = sr_legacy_match.iloc[0]['fdc_id']\n",
    "    print(f\"✓ Found SR Legacy match: fdc_id {fdc_id}\")\n",
    "    \n",
    "    # Step 2: Get nutrient data for this fdc_id\n",
    "    food_nutrients = food_nutrient_df[food_nutrient_df['fdc_id'] == fdc_id]\n",
    "    \n",
    "    if not food_nutrients.empty:\n",
    "        print(f\"✓ Found {len(food_nutrients)} nutrient entries\")\n",
    "        \n",
    "        # Step 3: Get nutrient names\n",
    "        nutrient_ids = food_nutrients['nutrient_id'].unique()\n",
    "        nutrient_names = nutrient_df[nutrient_df['id'].isin(nutrient_ids)]\n",
    "        \n",
    "        # Show top nutrients\n",
    "        merged_nutrients = food_nutrients.merge(\n",
    "            nutrient_names[['id', 'name', 'unit_name']], \n",
    "            left_on='nutrient_id', \n",
    "            right_on='id'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nNutrient data for {test_food}:\")\n",
    "        for _, nutrient in merged_nutrients.head(10).iterrows():\n",
    "            print(f\"  {nutrient['name']}: {nutrient['amount']} {nutrient['unit_name']}\")\n",
    "    else:\n",
    "        print(\"✗ No nutrient data found\")\n",
    "else:\n",
    "    print(f\"✗ No SR Legacy match for NDB {ndb_number}\")\n",
    "    # Show some SR Legacy NDB numbers for debugging\n",
    "    print(\"Sample SR Legacy NDB numbers:\", sr_legacy_food_df['NDB_number'].dropna().head().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b85a08-f85f-4c76-8c51-86c2df33349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING COMPLETE LINKING FUNCTIONS ===\n",
      "\n",
      "--- Testing avocado ---\n",
      "Found 23580 feature-intensity pairs for avocado\n",
      "Intensity summary: 23580 features, 2 samples\n",
      "Looking for NDB number 9037 for avocado\n",
      "✓ Found SR Legacy match: fdc_id 171705\n",
      "✓ Found 122 nutrient entries\n",
      "✓ Found 122 nutrients with names\n",
      "Top nutrients:\n",
      "  Fructose: 0.12 G\n",
      "  Carbohydrate, by difference: 8.53 G\n",
      "  Fatty acids, total monounsaturated: 9.799 G\n",
      "  Tocopherol, beta: 0.05 MG\n",
      "  Copper, Cu: 0.19 MG\n",
      "\n",
      "--- Testing persimmon ---\n",
      "Found 19560 feature-intensity pairs for persimmon\n",
      "Intensity summary: 19560 features, 2 samples\n",
      "Looking for NDB number 45299869 for persimmon\n",
      "No SR Legacy match for NDB 45299869\n",
      "\n",
      "--- Testing banana ---\n",
      "Found 17478 feature-intensity pairs for banana\n",
      "Intensity summary: 17478 features, 2 samples\n",
      "Looking for NDB number 9040 for banana\n",
      "✓ Found SR Legacy match: fdc_id 173944\n",
      "✓ Found 108 nutrient entries\n",
      "✓ Found 108 nutrients with names\n",
      "Top nutrients:\n",
      "  Manganese, Mn: 0.27 MG\n",
      "  Tocopherol, gamma: 0.02 MG\n",
      "  Vitamin A, RAE: 3.0 UG\n",
      "  Cholesterol: 0.0 MG\n",
      "  SFA 18:0: 0.005 G\n"
     ]
    }
   ],
   "source": [
    "# Create functions for complete linking\n",
    "def get_food_intensities(food_name, intensity_df, metadata_df):\n",
    "    \"\"\"\n",
    "    Get all feature intensities for all samples of a given food.\n",
    "    \n",
    "    Args:\n",
    "        food_name: Name of the food from sample_type_group5\n",
    "        intensity_df: Feature intensity matrix\n",
    "        metadata_df: Food metadata\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with Feature, filename, intensity columns\n",
    "    \"\"\"\n",
    "    # Get all samples for this food\n",
    "    food_samples = metadata_df[metadata_df['sample_type_group5'] == food_name]\n",
    "    \n",
    "    if food_samples.empty:\n",
    "        print(f\"No samples found for food: {food_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_intensities = []\n",
    "    \n",
    "    for _, sample in food_samples.iterrows():\n",
    "        filename = sample['filename']\n",
    "        \n",
    "        # Try both cases for peak area column\n",
    "        intensity_col_lower = f\"{filename} peak area\"\n",
    "        intensity_col_upper = f\"{filename} Peak area\"\n",
    "        \n",
    "        intensity_col = None\n",
    "        if intensity_col_lower in intensity_df.columns:\n",
    "            intensity_col = intensity_col_lower\n",
    "        elif intensity_col_upper in intensity_df.columns:\n",
    "            intensity_col = intensity_col_upper\n",
    "        \n",
    "        if intensity_col:\n",
    "            # Get intensities for this sample\n",
    "            sample_intensities = intensity_df[['Feature', intensity_col]].copy()\n",
    "            sample_intensities = sample_intensities.rename(columns={intensity_col: 'intensity'})\n",
    "            sample_intensities['filename'] = filename\n",
    "            \n",
    "            # Filter non-zero intensities\n",
    "            sample_intensities = sample_intensities[\n",
    "                (sample_intensities['intensity'] > 0) & \n",
    "                (sample_intensities['intensity'].notna())\n",
    "            ]\n",
    "            \n",
    "            all_intensities.append(sample_intensities)\n",
    "    \n",
    "    if all_intensities:\n",
    "        result = pd.concat(all_intensities, ignore_index=True)\n",
    "        print(f\"Found {len(result)} feature-intensity pairs for {food_name}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"No intensity data found for {food_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def get_food_nutrients_with_sr_legacy(food_name, metadata_df, sr_legacy_food_df, food_nutrient_df, nutrient_df):\n",
    "    \"\"\"\n",
    "    Get nutritional data for a food using NDB number -> SR Legacy -> fdc_id linking.\n",
    "    \n",
    "    Args:\n",
    "        food_name: Name of the food\n",
    "        metadata_df: Food metadata with NDB numbers\n",
    "        sr_legacy_food_df: SR Legacy food mapping\n",
    "        food_nutrient_df: USDA food_nutrient.csv\n",
    "        nutrient_df: USDA nutrient.csv\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with nutrient information\n",
    "    \"\"\"\n",
    "    # Get NDB number for this food\n",
    "    food_metadata = metadata_df[metadata_df['sample_type_group5'] == food_name]\n",
    "    ndb_numbers = food_metadata['ndb_number'].dropna().unique()\n",
    "    \n",
    "    if len(ndb_numbers) == 0:\n",
    "        print(f\"No NDB numbers found for {food_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Use the first NDB number\n",
    "    ndb_number = ndb_numbers[0]\n",
    "    print(f\"Looking for NDB number {ndb_number} for {food_name}\")\n",
    "    \n",
    "    # Step 1: Find fdc_id in SR Legacy food (convert to string for comparison)\n",
    "    sr_legacy_match = sr_legacy_food_df[sr_legacy_food_df['NDB_number'].astype(str) == str(ndb_number)]\n",
    "    \n",
    "    if sr_legacy_match.empty:\n",
    "        print(f\"No SR Legacy match for NDB {ndb_number}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    fdc_id = sr_legacy_match.iloc[0]['fdc_id']\n",
    "    print(f\"✓ Found SR Legacy match: fdc_id {fdc_id}\")\n",
    "    \n",
    "    # Step 2: Get nutrient data for this fdc_id\n",
    "    food_nutrients = food_nutrient_df[food_nutrient_df['fdc_id'] == fdc_id]\n",
    "    \n",
    "    if food_nutrients.empty:\n",
    "        print(f\"No nutrient data found for fdc_id {fdc_id}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"✓ Found {len(food_nutrients)} nutrient entries\")\n",
    "    \n",
    "    # Step 3: Get nutrient names\n",
    "    nutrient_ids = food_nutrients['nutrient_id'].unique()\n",
    "    nutrient_names = nutrient_df[nutrient_df['id'].isin(nutrient_ids)]\n",
    "    \n",
    "    # Merge nutrient data with names\n",
    "    result = food_nutrients.merge(\n",
    "        nutrient_names[['id', 'name', 'unit_name']], \n",
    "        left_on='nutrient_id', \n",
    "        right_on='id'\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Found {len(result)} nutrients with names\")\n",
    "    return result[['name', 'amount', 'unit_name']]\n",
    "\n",
    "# Test the functions\n",
    "print(\"=== TESTING COMPLETE LINKING FUNCTIONS ===\")\n",
    "\n",
    "# Get foods with NDB numbers\n",
    "foods_with_ndb = metadata_df[metadata_df['ndb_number'].notna()]['sample_type_group5'].unique()\n",
    "if len(foods_with_ndb) > 0:\n",
    "    test_foods = random.sample(list(foods_with_ndb), min(3, len(foods_with_ndb)))\n",
    "else:\n",
    "    test_foods = random_foods\n",
    "\n",
    "for food in test_foods:\n",
    "    print(f\"\\n--- Testing {food} ---\")\n",
    "    \n",
    "    # Get intensities\n",
    "    intensities = get_food_intensities(food, intensity_df, metadata_df)\n",
    "    if not intensities.empty:\n",
    "        print(f\"Intensity summary: {len(intensities)} features, {intensities['filename'].nunique()} samples\")\n",
    "    \n",
    "    # Get nutrients\n",
    "    nutrients = get_food_nutrients_with_sr_legacy(\n",
    "        food, metadata_df, sr_legacy_food_df, food_nutrient_df, nutrient_df\n",
    "    )\n",
    "    if not nutrients.empty:\n",
    "        print(\"Top nutrients:\")\n",
    "        for _, nutrient in nutrients.head(5).iterrows():\n",
    "            print(f\"  {nutrient['name']}: {nutrient['amount']} {nutrient['unit_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e14146-fef2-4d76-95a8-a36ce306e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY AND NEXT STEPS ===\n",
      "\n",
      "Corrected data linking process:\n",
      "1. Food name (sample_type_group5) -> multiple filenames (samples)\n",
      "2. Filename -> <filename> peak area / Peak area column in intensity matrix\n",
      "3. Feature ID + filename -> intensity value\n",
      "4. NDB number (int) -> SR Legacy food (NDB_number as str) -> fdc_id -> nutrient data\n",
      "\n",
      "Key corrections:\n",
      "- Handle both 'peak area' and 'Peak area' column names\n",
      "- Convert NDB number types: metadata (int) -> SR Legacy (str)\n",
      "- Use SR Legacy mapping: NDB_number -> fdc_id\n",
      "\n",
      "This creates the graph structure:\n",
      "- Molecule nodes: Feature IDs with intensity values\n",
      "- Food nodes: sample_type_group5 with nutritional profiles\n",
      "- Edges: (Feature, 'found_in', Food) with intensity weights\n",
      "\n",
      "Next steps:\n",
      "- Generate Spec2Vec embeddings for Feature IDs\n",
      "- Create nutritional feature vectors for foods\n",
      "- Build PyTorch Geometric HeteroData object\n",
      "- Implement HAN or GIN architecture\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SUMMARY AND NEXT STEPS ===\")\n",
    "print(\"\\nCorrected data linking process:\")\n",
    "print(\"1. Food name (sample_type_group5) -> multiple filenames (samples)\")\n",
    "print(\"2. Filename -> <filename> peak area / Peak area column in intensity matrix\")\n",
    "print(\"3. Feature ID + filename -> intensity value\")\n",
    "print(\"4. NDB number (int) -> SR Legacy food (NDB_number as str) -> fdc_id -> nutrient data\")\n",
    "\n",
    "print(\"\\nKey corrections:\")\n",
    "print(\"- Handle both 'peak area' and 'Peak area' column names\")\n",
    "print(\"- Convert NDB number types: metadata (int) -> SR Legacy (str)\")\n",
    "print(\"- Use SR Legacy mapping: NDB_number -> fdc_id\")\n",
    "\n",
    "print(\"\\nThis creates the graph structure:\")\n",
    "print(\"- Molecule nodes: Feature IDs with intensity values\")\n",
    "print(\"- Food nodes: sample_type_group5 with nutritional profiles\")\n",
    "print(\"- Edges: (Feature, 'found_in', Food) with intensity weights\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"- Generate Spec2Vec embeddings for Feature IDs\")\n",
    "print(\"- Create nutritional feature vectors for foods\")\n",
    "print(\"- Build PyTorch Geometric HeteroData object\")\n",
    "print(\"- Implement HAN or GIN architecture\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
